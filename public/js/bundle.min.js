!function(e,t){"object"==typeof exports&&"object"==typeof module?module.exports=t(require("onnxruntime-web")):"function"==typeof define&&define.amd?define(["onnxruntime-web"],t):"object"==typeof exports?exports.vad=t(require("onnxruntime-web")):e.vad=t(e.ort)}(self,e=>(()=>{"use strict";var t={485(e,t){Object.defineProperty(t,"__esModule",{value:!0}),t.baseAssetPath=void 0;let s="undefined"!=typeof window&&void 0!==window.document?window.document.currentScript:null,i="/";s&&(i=s.src.replace(/#.*$/,"").replace(/\?.*$/,"").replace(/\/[^\/]+$/,"/")),t.baseAssetPath=i},973(e,t){Object.defineProperty(t,"__esModule",{value:!0}),t.defaultModelFetcher=void 0,t.defaultModelFetcher=e=>fetch(e).then(e=>e.arrayBuffer())},362(e,t,s){Object.defineProperty(t,"__esModule",{value:!0}),t.FrameProcessor=t.validateOptions=t.defaultV5FrameProcessorOptions=t.defaultLegacyFrameProcessorOptions=void 0;let i=s(710),r=s(954),o=[512,1024,1536];t.defaultLegacyFrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.35,preSpeechPadFrames:1,redemptionFrames:8,frameSamples:1536,minSpeechFrames:3,submitUserSpeechOnPause:!1},t.defaultV5FrameProcessorOptions={positiveSpeechThreshold:.5,negativeSpeechThreshold:.35,preSpeechPadFrames:3,redemptionFrames:24,frameSamples:512,minSpeechFrames:9,submitUserSpeechOnPause:!1},t.validateOptions=function(e){o.includes(e.frameSamples)||i.log.warn("You are using an unusual frame size"),(e.positiveSpeechThreshold<0||e.positiveSpeechThreshold>1)&&i.log.error("positiveSpeechThreshold should be a number between 0 and 1"),(e.negativeSpeechThreshold<0||e.negativeSpeechThreshold>e.positiveSpeechThreshold)&&i.log.error("negativeSpeechThreshold should be between 0 and positiveSpeechThreshold"),e.preSpeechPadFrames<0&&i.log.error("preSpeechPadFrames should be positive"),e.redemptionFrames<0&&i.log.error("redemptionFrames should be positive")};let a=e=>{let t=e.reduce((e,t)=>(e.push(e.at(-1)+t.length),e),[0]),s=new Float32Array(t.at(-1));return e.forEach((e,i)=>{let r=t[i];s.set(e,r)}),s};t.FrameProcessor=class{constructor(e,t,s){this.modelProcessFunc=e,this.modelResetFunc=t,this.options=s,this.speaking=!1,this.redemptionCounter=0,this.active=!1,this.reset=()=>{this.speaking=!1,this.audioBuffer=[],this.modelResetFunc(),this.redemptionCounter=0},this.pause=()=>(this.active=!1,this.options.submitUserSpeechOnPause?this.endSegment():(this.reset(),{})),this.resume=()=>{this.active=!0},this.endSegment=()=>{let e=this.audioBuffer;this.audioBuffer=[];let t=this.speaking;this.reset();let s=e.reduce((e,t)=>e+ +t.isSpeech,0);if(t){if(s>=this.options.minSpeechFrames){let i=a(e.map(e=>e.frame));return{msg:r.Message.SpeechEnd,audio:i}}return{msg:r.Message.VADMisfire}}return{}},this.process=async e=>{if(!this.active)return{};let t=await this.modelProcessFunc(e);if(this.audioBuffer.push({frame:e,isSpeech:t.isSpeech>=this.options.positiveSpeechThreshold}),t.isSpeech>=this.options.positiveSpeechThreshold&&this.redemptionCounter&&(this.redemptionCounter=0),t.isSpeech>=this.options.positiveSpeechThreshold&&!this.speaking)return this.speaking=!0,{probs:t,msg:r.Message.SpeechStart,frame:e};if(t.isSpeech<this.options.negativeSpeechThreshold&&this.speaking&&++this.redemptionCounter>=this.options.redemptionFrames){this.redemptionCounter=0,this.speaking=!1;let s=this.audioBuffer;if(this.audioBuffer=[],s.reduce((e,t)=>e+ +t.isSpeech,0)>=this.options.minSpeechFrames){let i=a(s.map(e=>e.frame));return{probs:t,msg:r.Message.SpeechEnd,audio:i,frame:e}}return{probs:t,msg:r.Message.VADMisfire,frame:e}}if(!this.speaking)for(;this.audioBuffer.length>this.options.preSpeechPadFrames;)this.audioBuffer.shift();return{probs:t,frame:e}},this.audioBuffer=[],this.reset()}}},590:function(e,t,s){var i=this&&this.__createBinding||(Object.create?function(e,t,s,i){void 0===i&&(i=s);var r=Object.getOwnPropertyDescriptor(t,s);r&&!("get"in r?!t.__esModule:r.writable||r.configurable)||(r={enumerable:!0,get:function(){return t[s]}}),Object.defineProperty(e,i,r)}:function(e,t,s,i){void 0===i&&(i=s),e[i]=t[s]}),r=this&&this.__setModuleDefault||(Object.create?function(e,t){Object.defineProperty(e,"default",{enumerable:!0,value:t})}:function(e,t){e.default=t}),o=this&&this.__importStar||function(e){if(e&&e.__esModule)return e;var t={};if(null!=e)for(var s in e)"default"!==s&&Object.prototype.hasOwnProperty.call(e,s)&&i(t,e,s);return r(t,e),t};Object.defineProperty(t,"__esModule",{value:!0}),t.NonRealTimeVAD=t.Message=t.FrameProcessor=t.getDefaultRealTimeVADOptions=t.MicVAD=t.DEFAULT_MODEL=t.AudioNodeVAD=t.utils=t.defaultNonRealTimeVADOptions=void 0;let a=o(s(656)),n=s(485),h=s(973),l=s(362);Object.defineProperty(t,"FrameProcessor",{enumerable:!0,get:function(){return l.FrameProcessor}});let u=s(954);Object.defineProperty(t,"Message",{enumerable:!0,get:function(){return u.Message}});let d=s(202),c=s(787);t.defaultNonRealTimeVADOptions={modelURL:n.baseAssetPath+"silero_vad_legacy.onnx",modelFetcher:h.defaultModelFetcher};class p extends d.PlatformAgnosticNonRealTimeVAD{static async new(e={}){let{modelURL:s,modelFetcher:i}={...t.defaultNonRealTimeVADOptions,...e};return await this._new(()=>i(s),a,e)}}t.NonRealTimeVAD=p,t.utils={audioFileToArray:c.audioFileToArray,minFramesForTargetMS:c.minFramesForTargetMS,arrayBufferToBase64:c.arrayBufferToBase64,encodeWAV:c.encodeWAV};var f=s(746);Object.defineProperty(t,"AudioNodeVAD",{enumerable:!0,get:function(){return f.AudioNodeVAD}}),Object.defineProperty(t,"DEFAULT_MODEL",{enumerable:!0,get:function(){return f.DEFAULT_MODEL}}),Object.defineProperty(t,"MicVAD",{enumerable:!0,get:function(){return f.MicVAD}}),Object.defineProperty(t,"getDefaultRealTimeVADOptions",{enumerable:!0,get:function(){return f.getDefaultRealTimeVADOptions}})},710(e,t){Object.defineProperty(t,"__esModule",{value:!0}),t.log=t.LOG_PREFIX=void 0,t.LOG_PREFIX="[VAD]";let s=["error","debug","warn"].reduce((e,s)=>{var i;return e[s]=(i=s,(...e)=>{console[i](t.LOG_PREFIX,...e)}),e},{});t.log=s},954(e,t){var s,i;Object.defineProperty(t,"__esModule",{value:!0}),t.Message=void 0,(i=s||(t.Message=s={})).AudioFrame="AUDIO_FRAME",i.SpeechStart="SPEECH_START",i.VADMisfire="VAD_MISFIRE",i.SpeechEnd="SPEECH_END",i.SpeechStop="SPEECH_STOP"},650(e,t){Object.defineProperty(t,"__esModule",{value:!0})},559:function(e,t,s){var i=this&&this.__createBinding||(Object.create?function(e,t,s,i){void 0===i&&(i=s);var r=Object.getOwnPropertyDescriptor(t,s);r&&!("get"in r?!t.__esModule:r.writable||r.configurable)||(r={enumerable:!0,get:function(){return t[s]}}),Object.defineProperty(e,i,r)}:function(e,t,s,i){void 0===i&&(i=s),e[i]=t[s]}),r=this&&this.__exportStar||function(e,t){for(var s in e)"default"===s||Object.prototype.hasOwnProperty.call(t,s)||i(t,e,s)};Object.defineProperty(t,"__esModule",{value:!0}),t.SileroV5=t.SileroLegacy=void 0,r(s(650),t);var o=s(143);Object.defineProperty(t,"SileroLegacy",{enumerable:!0,get:function(){return o.SileroLegacy}});var a=s(508);Object.defineProperty(t,"SileroV5",{enumerable:!0,get:function(){return a.SileroV5}})},143(e,t,s){var i;Object.defineProperty(t,"__esModule",{value:!0}),t.SileroLegacy=void 0;let r=s(710);class o{constructor(e,t,s,i,r){this.ortInstance=e,this._session=t,this._h=s,this._c=i,this._sr=r,this.reset_state=()=>{let e=Array(128).fill(0);this._h=new this.ortInstance.Tensor("float32",e,[2,1,64]),this._c=new this.ortInstance.Tensor("float32",e,[2,1,64])},this.process=async e=>{let t={input:new this.ortInstance.Tensor("float32",e,[1,e.length]),h:this._h,c:this._c,sr:this._sr},s=await this._session.run(t);this._h=s.hn,this._c=s.cn;let[i]=s.output?.data;return{notSpeech:1-i,isSpeech:i}}}}t.SileroLegacy=o,i=o,o.new=async(e,t)=>{r.log.debug("initializing vad");let s=await t(),o=await e.InferenceSession.create(s),a=new e.Tensor("int64",[16000n]),n=Array(128).fill(0),h=new e.Tensor("float32",n,[2,1,64]),l=new e.Tensor("float32",n,[2,1,64]);return r.log.debug("vad is initialized"),new i(e,o,h,l,a)}},508(e,t,s){var i;Object.defineProperty(t,"__esModule",{value:!0}),t.SileroV5=void 0;let r=s(710);function o(e){let t=Array(256).fill(0);return new e.Tensor("float32",t,[2,1,128])}class a{constructor(e,t,s,i){this._session=e,this._state=t,this._sr=s,this.ortInstance=i,this.reset_state=()=>{this._state=o(this.ortInstance)},this.process=async e=>{let t={input:new this.ortInstance.Tensor("float32",e,[1,e.length]),state:this._state,sr:this._sr},s=await this._session.run(t);this._state=s.stateN;let[i]=s.output?.data;return{notSpeech:1-i,isSpeech:i}}}}t.SileroV5=a,i=a,a.new=async(e,t)=>{r.log.debug("Loading VAD...");let s=await t(),a=await e.InferenceSession.create(s),n=new e.Tensor("int64",[16000n]),h=o(e);return r.log.debug("...finished loading VAD"),new i(a,h,n,e)}},202(e,t,s){Object.defineProperty(t,"__esModule",{value:!0}),t.PlatformAgnosticNonRealTimeVAD=t.defaultNonRealTimeVADOptions=void 0;let i=s(362),r=s(954),o=s(559),a=s(825);t.defaultNonRealTimeVADOptions={...i.defaultLegacyFrameProcessorOptions,ortConfig:void 0},t.PlatformAgnosticNonRealTimeVAD=class{static async _new(e,s,i={}){let r={...t.defaultNonRealTimeVADOptions,...i};void 0!==r.ortConfig&&r.ortConfig(s);let o=new this(e,s,r);return await o.init(),o}constructor(e,t,s){this.modelFetcher=e,this.ort=t,this.options=s,this.init=async()=>{let e=await o.SileroLegacy.new(this.ort,this.modelFetcher);this.frameProcessor=new i.FrameProcessor(e.process,e.reset_state,{frameSamples:this.options.frameSamples,positiveSpeechThreshold:this.options.positiveSpeechThreshold,negativeSpeechThreshold:this.options.negativeSpeechThreshold,redemptionFrames:this.options.redemptionFrames,preSpeechPadFrames:this.options.preSpeechPadFrames,minSpeechFrames:this.options.minSpeechFrames,submitUserSpeechOnPause:this.options.submitUserSpeechOnPause}),this.frameProcessor.resume()},this.run=async function*(e,t){let s={nativeSampleRate:t,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples},i=new a.Resampler(s),o=0,n=0,h=0;for await(let l of i.stream(e)){let{msg:u,audio:d}=await this.frameProcessor.process(l);switch(u){case r.Message.SpeechStart:o=h*this.options.frameSamples/16;break;case r.Message.SpeechEnd:yield{audio:d,start:o,end:n=(h+1)*this.options.frameSamples/16}}h++}let{msg:c,audio:p}=this.frameProcessor.endSegment();c==r.Message.SpeechEnd&&(yield{audio:p,start:o,end:h*this.options.frameSamples/16})},(0,i.validateOptions)(s)}}},746:function(e,t,s){var i=this&&this.__createBinding||(Object.create?function(e,t,s,i){void 0===i&&(i=s);var r=Object.getOwnPropertyDescriptor(t,s);r&&!("get"in r?!t.__esModule:r.writable||r.configurable)||(r={enumerable:!0,get:function(){return t[s]}}),Object.defineProperty(e,i,r)}:function(e,t,s,i){void 0===i&&(i=s),e[i]=t[s]}),r=this&&this.__setModuleDefault||(Object.create?function(e,t){Object.defineProperty(e,"default",{enumerable:!0,value:t})}:function(e,t){e.default=t}),o=this&&this.__importStar||function(e){if(e&&e.__esModule)return e;var t={};if(null!=e)for(var s in e)"default"!==s&&Object.prototype.hasOwnProperty.call(e,s)&&i(t,e,s);return r(t,e),t};Object.defineProperty(t,"__esModule",{value:!0}),t.AudioNodeVAD=t.MicVAD=t.getDefaultRealTimeVADOptions=t.ort=t.DEFAULT_MODEL=void 0;let a=o(s(656)),n=s(973),h=s(362),l=s(710),u=s(954),d=s(559),c=s(825);t.DEFAULT_MODEL="legacy",t.ort=a,t.getDefaultRealTimeVADOptions=e=>({..."v5"===e?h.defaultV5FrameProcessorOptions:h.defaultLegacyFrameProcessorOptions,onFrameProcessed(e){},onVADMisfire(){l.log.debug("VAD misfire")},onSpeechStart(){l.log.debug("Detected speech start")},onSpeechEnd(){l.log.debug("Detected speech end")},baseAssetPath:"https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/",onnxWASMBasePath:"https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/",stream:void 0,ortConfig:void 0,model:t.DEFAULT_MODEL,workletOptions:{}});class p{static async new(e={}){let s={...(0,t.getDefaultRealTimeVADOptions)(e.model??t.DEFAULT_MODEL),...e},i;(0,h.validateOptions)(s),i=void 0===s.stream?await navigator.mediaDevices.getUserMedia({audio:{...s.additionalAudioConstraints,channelCount:1,echoCancellation:!0,autoGainControl:!0,noiseSuppression:!0}}):s.stream;let r=new AudioContext,o=new MediaStreamAudioSourceNode(r,{mediaStream:i}),a=await f.new(r,s);return a.receive(o),new p(s,r,i,a,o)}constructor(e,t,s,i,r,o=!1){this.options=e,this.audioContext=t,this.stream=s,this.audioNodeVAD=i,this.sourceNode=r,this.listening=o,this.pause=()=>{this.audioNodeVAD.pause(),this.listening=!1},this.start=()=>{this.audioNodeVAD.start(),this.listening=!0},this.destroy=()=>{this.listening&&this.pause(),void 0===this.options.stream&&this.stream.getTracks().forEach(e=>e.stop()),this.sourceNode.disconnect(),this.audioNodeVAD.destroy(),this.audioContext.close()}}}t.MicVAD=p;class f{static async new(e,s={}){let i={...(0,t.getDefaultRealTimeVADOptions)(s.model??t.DEFAULT_MODEL),...s};(0,h.validateOptions)(i),t.ort.env.wasm.wasmPaths=i.onnxWASMBasePath,void 0!==i.ortConfig&&i.ortConfig(t.ort);let r="v5"===i.model?"silero_vad_v5.onnx":"silero_vad_legacy.onnx",o=i.baseAssetPath+r,a="v5"===i.model?d.SileroV5.new:d.SileroLegacy.new,l;try{l=await a(t.ort,()=>(0,n.defaultModelFetcher)(o))}catch(u){throw console.error(`Encountered an error while loading model file ${o}`),u}let c=new h.FrameProcessor(l.process,l.reset_state,{frameSamples:i.frameSamples,positiveSpeechThreshold:i.positiveSpeechThreshold,negativeSpeechThreshold:i.negativeSpeechThreshold,redemptionFrames:i.redemptionFrames,preSpeechPadFrames:i.preSpeechPadFrames,minSpeechFrames:i.minSpeechFrames,submitUserSpeechOnPause:i.submitUserSpeechOnPause}),p=new f(e,i,c);return await p.setupAudioNode(),p}constructor(e,t,s){this.ctx=e,this.options=t,this.bufferIndex=0,this.pause=()=>{let e=this.frameProcessor.pause();this.handleFrameProcessorEvent(e)},this.start=()=>{this.frameProcessor.resume()},this.receive=e=>{e.connect(this.audioNode)},this.processFrame=async e=>{let t=await this.frameProcessor.process(e);this.handleFrameProcessorEvent(t)},this.handleFrameProcessorEvent=e=>{switch(void 0!==e.probs&&this.options.onFrameProcessed(e.probs,e.frame),e.msg){case u.Message.SpeechStart:this.options.onSpeechStart();break;case u.Message.VADMisfire:this.options.onVADMisfire();break;case u.Message.SpeechEnd:this.options.onSpeechEnd(e.audio)}},this.destroy=()=>{this.audioNode instanceof AudioWorkletNode&&this.audioNode.port.postMessage({message:u.Message.SpeechStop}),this.audioNode.disconnect(),this.gainNode?.disconnect()},this.frameProcessor=s}async setupAudioNode(){if("audioWorklet"in this.ctx&&"function"==typeof AudioWorkletNode)try{let e=this.options.baseAssetPath+"vad.worklet.bundle.min.js";await this.ctx.audioWorklet.addModule(e);let t=this.options.workletOptions??{};return t.processorOptions={...t.processorOptions??{},frameSamples:this.options.frameSamples},this.audioNode=new AudioWorkletNode(this.ctx,"vad-helper-worklet",t),void(this.audioNode.port.onmessage=async e=>{if(e.data?.message===u.Message.AudioFrame){let t=e.data.data;t instanceof ArrayBuffer||(t=new ArrayBuffer(e.data.data.byteLength),new Uint8Array(t).set(new Uint8Array(e.data.data)));let s=new Float32Array(t);await this.processFrame(s)}})}catch(s){console.log("AudioWorklet setup failed, falling back to ScriptProcessor",s)}this.resampler=new c.Resampler({nativeSampleRate:this.ctx.sampleRate,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples??480}),this.audioNode=this.ctx.createScriptProcessor(4096,1,1),this.gainNode=this.ctx.createGain(),this.gainNode.gain.value=0;let i=!1;this.audioNode.onaudioprocess=async e=>{if(!i){i=!0;try{let t=e.inputBuffer.getChannelData(0);if(e.outputBuffer.getChannelData(0).fill(0),this.resampler){let s=this.resampler.process(t);for(let r of s)await this.processFrame(r)}}catch(o){console.error("Error processing audio:",o)}finally{i=!1}}},this.audioNode.connect(this.gainNode),this.gainNode.connect(this.ctx.destination)}}t.AudioNodeVAD=f},825(e,t,s){Object.defineProperty(t,"__esModule",{value:!0}),t.Resampler=void 0;let i=s(710);t.Resampler=class{constructor(e){this.options=e,this.process=e=>{let t=[];for(let s of e)for(this.inputBuffer.push(s);this.hasEnoughDataForFrame();){let i=this.generateOutputFrame();t.push(i)}return t},this.stream=async function*(e){for(let t of e)for(this.inputBuffer.push(t);this.hasEnoughDataForFrame();){let s=this.generateOutputFrame();yield s}},e.nativeSampleRate<16e3&&i.log.error("nativeSampleRate is too low. Should have 16000 = targetSampleRate <= nativeSampleRate"),this.inputBuffer=[]}hasEnoughDataForFrame(){return this.inputBuffer.length*this.options.targetSampleRate/this.options.nativeSampleRate>=this.options.targetFrameSize}generateOutputFrame(){let e=new Float32Array(this.options.targetFrameSize),t=0,s=0;for(;t<this.options.targetFrameSize;){let i=0,r=0;for(;s<Math.min(this.inputBuffer.length,(t+1)*this.options.nativeSampleRate/this.options.targetSampleRate);){let o=this.inputBuffer[s];void 0!==o&&(i+=o,r++),s++}e[t]=i/r,t++}return this.inputBuffer=this.inputBuffer.slice(s),e}}},787(e,t){function s(e,t,s){for(var i=0;i<s.length;i++)e.setUint8(t+i,s.charCodeAt(i))}Object.defineProperty(t,"__esModule",{value:!0}),t.audioFileToArray=t.encodeWAV=t.arrayBufferToBase64=t.minFramesForTargetMS=void 0,t.minFramesForTargetMS=function(e,t,s=16e3){return Math.ceil(e*s/1e3/t)},t.arrayBufferToBase64=function(e){let t=new Uint8Array(e),s=t.byteLength,i=Array(s);for(var r=0;r<s;r++){let o=t[r];if(void 0===o)break;i[r]=String.fromCharCode(o)}return btoa(i.join(""))},t.encodeWAV=function(e,t=3,i=16e3,r=1,o=32){var a=o/8,n=r*a,h=new ArrayBuffer(44+e.length*a),l=new DataView(h);return s(l,0,"RIFF"),l.setUint32(4,36+e.length*a,!0),s(l,8,"WAVE"),s(l,12,"fmt "),l.setUint32(16,16,!0),l.setUint16(20,t,!0),l.setUint16(22,r,!0),l.setUint32(24,i,!0),l.setUint32(28,i*n,!0),l.setUint16(32,n,!0),l.setUint16(34,o,!0),s(l,36,"data"),l.setUint32(40,e.length*a,!0),1===t?function(e,t,s){for(var i=0;i<s.length;i++,t+=2){var r=Math.max(-1,Math.min(1,s[i]));e.setInt16(t,r<0?32768*r:32767*r,!0)}}(l,44,e):function(e,t,s){for(var i=0;i<s.length;i++,t+=4)e.setFloat32(t,s[i],!0)}(l,44,e),h},t.audioFileToArray=async function(e){let t=new OfflineAudioContext(1,1,44100),s=new FileReader,i=null;if(await new Promise(r=>{s.addEventListener("loadend",e=>{let o=s.result;t.decodeAudioData(o,e=>{i=e,t.startRendering().then(e=>{console.log("Rendering completed successfully"),r()}).catch(e=>{console.error(`Rendering failed: ${e}`)})},e=>{console.log(`Error with decoding audio data: ${e}`)})}),s.readAsArrayBuffer(e)}),null===i)throw Error("some shit");let r=i,o=new Float32Array(r.length);for(let a=0;a<r.length;a++)for(let n=0;n<r.numberOfChannels;n++)o[a]+=r.getChannelData(n)[a];return{audio:o,sampleRate:r.sampleRate}}},656(t){t.exports=e}},s={};return function e(i){var r=s[i];if(void 0!==r)return r.exports;var o=s[i]={exports:{}};return t[i].call(o.exports,o,o.exports,e),o.exports}(590)})());